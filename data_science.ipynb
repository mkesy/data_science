{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_import\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.externals import joblib\n",
    "#end_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "clf = svm.SVC()\n",
    "x, y = iris.data, iris.target\n",
    "columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "\n",
    "data = pd.DataFrame(x, columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_prediction\n",
    "def multiply(attr):\n",
    "    return attr * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(raw_array, to_df=False):\n",
    "    columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "    data = pd.DataFrame(raw_array, columns = columns)\n",
    "    data['feature_1'] = data['petal_length'].apply(multiply)\n",
    "    \n",
    "    if to_df:\n",
    "        return data\n",
    "    else: \n",
    "        return data.values\n",
    "\n",
    "def predict(featurized_array):\n",
    "    return clf.predict(featurized_array)\n",
    "#end_prediction\n",
    "    \n",
    "# featurized = featurize([[0,3,4,5]])\n",
    "# predict(featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_featurized = featurize(data, True)\n",
    "#print(data_featurized[data_featurized.columns[:7]].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_featurized, iris.target_names[y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calculate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_featurized['prediction'] = predict(data_featurized[data_featurized.columns[:7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width  feature_1  \\\n",
       "0             5.1          3.5           1.4          0.2        2.8   \n",
       "1             4.9          3.0           1.4          0.2        2.8   \n",
       "2             4.7          3.2           1.3          0.2        2.6   \n",
       "3             4.6          3.1           1.5          0.2        3.0   \n",
       "4             5.0          3.6           1.4          0.2        2.8   \n",
       "5             5.4          3.9           1.7          0.4        3.4   \n",
       "6             4.6          3.4           1.4          0.3        2.8   \n",
       "7             5.0          3.4           1.5          0.2        3.0   \n",
       "8             4.4          2.9           1.4          0.2        2.8   \n",
       "9             4.9          3.1           1.5          0.1        3.0   \n",
       "10            5.4          3.7           1.5          0.2        3.0   \n",
       "11            4.8          3.4           1.6          0.2        3.2   \n",
       "12            4.8          3.0           1.4          0.1        2.8   \n",
       "13            4.3          3.0           1.1          0.1        2.2   \n",
       "14            5.8          4.0           1.2          0.2        2.4   \n",
       "15            5.7          4.4           1.5          0.4        3.0   \n",
       "16            5.4          3.9           1.3          0.4        2.6   \n",
       "17            5.1          3.5           1.4          0.3        2.8   \n",
       "18            5.7          3.8           1.7          0.3        3.4   \n",
       "19            5.1          3.8           1.5          0.3        3.0   \n",
       "20            5.4          3.4           1.7          0.2        3.4   \n",
       "21            5.1          3.7           1.5          0.4        3.0   \n",
       "22            4.6          3.6           1.0          0.2        2.0   \n",
       "23            5.1          3.3           1.7          0.5        3.4   \n",
       "24            4.8          3.4           1.9          0.2        3.8   \n",
       "25            5.0          3.0           1.6          0.2        3.2   \n",
       "26            5.0          3.4           1.6          0.4        3.2   \n",
       "27            5.2          3.5           1.5          0.2        3.0   \n",
       "28            5.2          3.4           1.4          0.2        2.8   \n",
       "29            4.7          3.2           1.6          0.2        3.2   \n",
       "..            ...          ...           ...          ...        ...   \n",
       "120           6.9          3.2           5.7          2.3       11.4   \n",
       "121           5.6          2.8           4.9          2.0        9.8   \n",
       "122           7.7          2.8           6.7          2.0       13.4   \n",
       "123           6.3          2.7           4.9          1.8        9.8   \n",
       "124           6.7          3.3           5.7          2.1       11.4   \n",
       "125           7.2          3.2           6.0          1.8       12.0   \n",
       "126           6.2          2.8           4.8          1.8        9.6   \n",
       "127           6.1          3.0           4.9          1.8        9.8   \n",
       "128           6.4          2.8           5.6          2.1       11.2   \n",
       "129           7.2          3.0           5.8          1.6       11.6   \n",
       "130           7.4          2.8           6.1          1.9       12.2   \n",
       "131           7.9          3.8           6.4          2.0       12.8   \n",
       "132           6.4          2.8           5.6          2.2       11.2   \n",
       "133           6.3          2.8           5.1          1.5       10.2   \n",
       "134           6.1          2.6           5.6          1.4       11.2   \n",
       "135           7.7          3.0           6.1          2.3       12.2   \n",
       "136           6.3          3.4           5.6          2.4       11.2   \n",
       "137           6.4          3.1           5.5          1.8       11.0   \n",
       "138           6.0          3.0           4.8          1.8        9.6   \n",
       "139           6.9          3.1           5.4          2.1       10.8   \n",
       "140           6.7          3.1           5.6          2.4       11.2   \n",
       "141           6.9          3.1           5.1          2.3       10.2   \n",
       "142           5.8          2.7           5.1          1.9       10.2   \n",
       "143           6.8          3.2           5.9          2.3       11.8   \n",
       "144           6.7          3.3           5.7          2.5       11.4   \n",
       "145           6.7          3.0           5.2          2.3       10.4   \n",
       "146           6.3          2.5           5.0          1.9       10.0   \n",
       "147           6.5          3.0           5.2          2.0       10.4   \n",
       "148           6.2          3.4           5.4          2.3       10.8   \n",
       "149           5.9          3.0           5.1          1.8       10.2   \n",
       "\n",
       "     prediction  \n",
       "0        setosa  \n",
       "1        setosa  \n",
       "2        setosa  \n",
       "3        setosa  \n",
       "4        setosa  \n",
       "5        setosa  \n",
       "6        setosa  \n",
       "7        setosa  \n",
       "8        setosa  \n",
       "9        setosa  \n",
       "10       setosa  \n",
       "11       setosa  \n",
       "12       setosa  \n",
       "13       setosa  \n",
       "14       setosa  \n",
       "15       setosa  \n",
       "16       setosa  \n",
       "17       setosa  \n",
       "18       setosa  \n",
       "19       setosa  \n",
       "20       setosa  \n",
       "21       setosa  \n",
       "22       setosa  \n",
       "23       setosa  \n",
       "24       setosa  \n",
       "25       setosa  \n",
       "26       setosa  \n",
       "27       setosa  \n",
       "28       setosa  \n",
       "29       setosa  \n",
       "..          ...  \n",
       "120   virginica  \n",
       "121   virginica  \n",
       "122   virginica  \n",
       "123   virginica  \n",
       "124   virginica  \n",
       "125   virginica  \n",
       "126  versicolor  \n",
       "127   virginica  \n",
       "128   virginica  \n",
       "129   virginica  \n",
       "130   virginica  \n",
       "131   virginica  \n",
       "132   virginica  \n",
       "133   virginica  \n",
       "134   virginica  \n",
       "135   virginica  \n",
       "136   virginica  \n",
       "137   virginica  \n",
       "138   virginica  \n",
       "139   virginica  \n",
       "140   virginica  \n",
       "141   virginica  \n",
       "142   virginica  \n",
       "143   virginica  \n",
       "144   virginica  \n",
       "145   virginica  \n",
       "146   virginica  \n",
       "147   virginica  \n",
       "148   virginica  \n",
       "149   virginica  \n",
       "\n",
       "[150 rows x 6 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_featurized.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dump the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'classifier.pkl', protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
